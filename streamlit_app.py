import streamlit as st
from PIL import Image
# import cv2
# import mediapipe as mp
# import numpy as np
# import tensorflow as tf
# import time
# from collections import deque



# From local file
# st.header("Display Local Image")
# image = Image.open("2(1).png")
# st.image(image, caption="Local Image", use_column_width=True)


# try:
#     # img = Image.open("2(1).png")
#     img = ("2(1).png")
#     st.image(img, caption="Opened with PIL")
# except Exception as e:
#     st.error(f"Failed to open image with PIL: {e}")



st.title("Sign Language Translator")

# st.image("2(1).png")

# Load model
# model = tf.keras.models.load_model("model.keras", compile=False)
# labels = [chr(i) for i in range(65, 91)]

# #classes 
# classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',
#            'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V',
#            'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']

# # MediaPipe hands
# mp_hands = mp.solutions.hands
# hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1)



st.write(
    "
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    Character:"
)

st.write("Hello World ")

